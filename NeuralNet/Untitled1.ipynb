{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "NeuralNet instance has no attribute 'preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-12741c71a7c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneural_network\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adultTrain.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-ac533e55c452>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train, activation, header, h1, h2)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mraw_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# TODO: Remember to implement the preprocess method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mncols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: NeuralNet instance has no attribute 'preprocess'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, train, activation,header = True, h1 = 4, h2 = 2):\n",
    "\n",
    "        np.random.seed(1)\n",
    "        # train refers to the training dataset\n",
    "        # test refers to the testing dataset\n",
    "        # h1 and h2 represent the number of nodes in 1st and 2nd hidden layers\n",
    "\n",
    "        raw_input = pd.read_csv(train, header=None)\n",
    "        # TODO: Remember to implement the preprocess method\n",
    "        train_dataset = self.preprocess(raw_input)\n",
    "        ncols = len(train_dataset.columns)\n",
    "        nrows = len(train_dataset.index)\n",
    "        self.X = train_dataset.iloc[:, 0:(ncols -1)].values.reshape(nrows, ncols-1)\n",
    "        self.y = train_dataset.iloc[:, (ncols-1)].values.reshape(nrows, 1)\n",
    "        self.activation = activation\n",
    "\n",
    "        #\n",
    "        # Find number of input and output layers from the dataset\n",
    "        #\n",
    "        input_layer_size = len(self.X[0])\n",
    "        if not isinstance(self.y[0], np.ndarray):\n",
    "            output_layer_size = 1\n",
    "        else:\n",
    "            output_layer_size = len(self.y[0])\n",
    "\n",
    "        # assign random weights to matrices in network\n",
    "        # number of weights connecting layers = (no. of nodes in previous layer) x (no. of nodes in following layer)\n",
    "        self.w01 = 2 * np.random.random((input_layer_size, h1)) - 1\n",
    "        self.X01 = self.X\n",
    "        self.delta01 = np.zeros((input_layer_size, h1))\n",
    "        self.w12 = 2 * np.random.random((h1, h2)) - 1\n",
    "        self.X12 = np.zeros((len(self.X), h1))\n",
    "        self.delta12 = np.zeros((h1, h2))\n",
    "        self.w23 = 2 * np.random.random((h2, output_layer_size)) - 1\n",
    "        self.X23 = np.zeros((len(self.X), h2))\n",
    "        self.delta23 = np.zeros((h2, output_layer_size))\n",
    "        self.deltaOut = np.zeros((output_layer_size, 1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-19-239988d7a4a5>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-239988d7a4a5>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    def __sigmoid(self, x):\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def __activation(self, x):\n",
    "        activation = self.activation\n",
    "        if activation == \"sigmoid\":\n",
    "            out1 = self.__sigmoid(x)\n",
    "        elif activation == \"tanh\":\n",
    "            out1 = self.__tanh(x)\n",
    "        elif activation == \"ReLu\":\n",
    "            out1 = self.__relu(x)\n",
    "\n",
    "        return out1\n",
    "\n",
    "    # sigmoid function\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # tanh function\n",
    "    def __tanh(self, x):\n",
    "    \treturn 1 - 2 / (1 + np.exp(2 * x))\n",
    "\n",
    "    # ReLu function\n",
    "    def __relu(self, x):\n",
    "    \treturn np.maximum(0, x)\n",
    "\n",
    "    #\n",
    "    # TODO: Define the function for tanh, ReLu and their derivatives\n",
    "    #\n",
    "    def __activation_derivative(self, x):\n",
    "        activation = self.activation\n",
    "        if activation == \"sigmoid\":\n",
    "            self.__sigmoid_derivative(x)\n",
    "        elif activation == \"tanh\":\n",
    "        \tself.__tanh_derivative(x)\n",
    "        elif activation == \"ReLu\":\n",
    "        \tself.__relu_derivative(x)\n",
    "\n",
    "    # derivative of sigmoid function, indicates confidence about existing weight\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # derivative of tanh function\n",
    "    def __tanh_derivative(self, x):\n",
    "    \treturn 1-x * x\n",
    "\n",
    "    # derivative of ReLu function  \n",
    "    # def __relu_derivative(self, x):\n",
    "    #     for c in range(len(x)):\n",
    "    #         for r in range(len(x[0])):\n",
    "    #             if x[c][r] > 0:\n",
    "    #                 x[c][r] = 1\n",
    "    #             else:\n",
    "    #                 x[c][r] = 0\n",
    "\n",
    "    #     return x\n",
    "    def __relu_derivative(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    #\n",
    "    # TODO: Write code for pre-processing the dataset, which would include standardization, normalization,\n",
    "    #   categorical to numerical, etc\n",
    "    # Using Label Encoding to transform categorical to numerical\n",
    "    # NA data is represented by the current column mean\n",
    "    # Numerical data is transformed by its mean and sd\n",
    "\n",
    "    def preprocess(self, X):\n",
    "    \toeDF = X.copy()\n",
    "    \tnum = X.shape[0]\n",
    "\n",
    "    \tfor column in X:\n",
    "    \t\tif X[column].dtype == 'object':\n",
    "    \t\t\toeDF[column] = oeDF[column].astype('category').cat.codes\n",
    "    \t\telse:\n",
    "    \t\t\ttemp = oeDF.iloc[:num-1, column].fillna(X[column].mean())\n",
    "    \t\t\tmean = temp.mean()\n",
    "    \t\t\tstd = temp.std()\n",
    "    \t\t\t# oeDF[column] = (oeDF[column] * 10- mean)/std\n",
    "\n",
    "    \tindexedTrain = oeDF.head(X.shape[0])\n",
    "\n",
    "        return indexedTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(self, max_iterations = 5, learning_rate = 0.1):\n",
    "        for iteration in range(max_iterations):\n",
    "            out = self.forward_pass(self.X)\n",
    "            error = 0.5 * np.power((out - self.y), 2)\n",
    "            self.backward_pass(out)\n",
    "            update_layer2 = learning_rate * self.X23.T.dot(self.deltaOut)\n",
    "            update_layer1 = learning_rate * self.X12.T.dot(self.delta23)\n",
    "            update_input = learning_rate * self.X01.T.dot(self.delta12)\n",
    "\n",
    "            self.w23 += update_layer2\n",
    "            self.w12 += update_layer1\n",
    "            self.w01 += update_input\n",
    "\n",
    "\n",
    "\n",
    "        print(\"After \" + str(max_iterations) + \" iterations, the total error is \" + str(np.sum(error)))\n",
    "        print(\"The final weight vectors are (starting from input to output layers)\")\n",
    "        print(\"The first layer weight vectors: \")\n",
    "        print(self.w01)\n",
    "        print(\"The second layer weight vectors: \")\n",
    "        print(self.w12)\n",
    "        print(\"The third layer weight vectors: \")\n",
    "        print(self.w23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(self, X):\n",
    "        # pass our inputs through our neural network\n",
    "        in1 = np.dot(X, self.w01)\n",
    "        self.X12 = self.__activation(in1)\n",
    "        in2 = np.dot(self.X12, self.w12)\n",
    "        self.X23 = self.__activation(in2)\n",
    "        in3 = np.dot(self.X23, self.w23)\n",
    "        out = self.__activation(in3)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def backward_pass(self, out):\n",
    "        # pass our inputs through our neural network\n",
    "        self.compute_output_delta(out, self.activation)\n",
    "        self.compute_hidden_layer2_delta(self.activation)\n",
    "        self.compute_hidden_layer1_delta(self.activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def compute_output_delta(self, out, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_output = (self.y - out) * (self.__sigmoid_derivative(out))\n",
    "        elif activation == \"tanh\":\n",
    "        \tdelta_output = (self.y - out) * (self.__tanh_derivative(out))\n",
    "        elif activation == \"ReLu\":\n",
    "            delta_output = (self.y - out) * (self.__relu_derivative(out))\n",
    "\n",
    "        self.deltaOut = delta_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hidden_layer2_delta(self, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_hidden_layer2 = (self.deltaOut.dot(self.w23.T)) * (self.__sigmoid_derivative(self.X23))\n",
    "        elif activation == \"tanh\":\n",
    "            delta_hidden_layer2 = (self.deltaOut.dot(self.w23.T)) * (self.__tanh_derivative(self.X23))\n",
    "        elif activation == \"ReLu\":\n",
    "            delta_hidden_layer2 = (self.deltaOut.dot(self.w23.T)) * (self.__relu_derivative(self.X23))   \n",
    "\n",
    "        self.delta23 = delta_hidden_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hidden_layer1_delta(self, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_hidden_layer1 = (self.delta23.dot(self.w12.T)) * (self.__sigmoid_derivative(self.X12))\n",
    "        elif activation == \"tanh\":\n",
    "            delta_hidden_layer1 = (self.delta23.dot(self.w12.T)) * (self.__tanh_derivative(self.X12))\n",
    "        elif activation == \"ReLu\":\n",
    "            delta_hidden_layer1 = (self.delta23.dot(self.w12.T)) * (self.__relu_derivative(self.X12))\n",
    "\n",
    "        self.delta12 = delta_hidden_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_input_layer_delta(self, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_input_layer = np.multiply(self.__sigmoid_derivative(self.X01), self.delta01.dot(self.w01.T))\n",
    "        elif activation == \"tanh\":\n",
    "            delta_input_layer = np.multiply(self.__tanh_derivative(self.X01), self.delta01.dot(self.w01.T))\n",
    "        elif activation == \"ReLu\":\n",
    "            delta_input_layer = np.multiply(self.__relu_derivative(self.X01), self.delta01.dot(self.w01.T))\n",
    "\n",
    "        self.delta01 = delta_input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-188a4185e8ee>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-188a4185e8ee>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    neural_network = NeuralNet(\"adultTrain.csv\", \"sigmoid\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "     \n",
    "    \n",
    "    def predict(self, test, header = True):\n",
    "\n",
    "    \traw_test_input = pd.read_csv(test, header=None)\n",
    "        # TODO: Remember to implement the preprocess method\n",
    "        test_dataset = self.preprocess(raw_test_input)\n",
    "        test_ncols = len(test_dataset.columns)\n",
    "        test_nrows = len(test_dataset.index)\n",
    "\n",
    "        test_Y = test_dataset.iloc[:, (test_ncols-1)].values.reshape(test_nrows, 1)\n",
    "        \n",
    "        test_X = test_dataset.iloc[:, 0:(test_ncols-1)].values.reshape(test_nrows, test_ncols-1)\n",
    "\n",
    "        test_out = self.forward_pass(test_X)\n",
    "        test_error = 0.5 * np.power((test_Y - test_out), 2)\n",
    "\n",
    "\n",
    "        return np.sum(test_error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network =NeuralNet(\"adultTrain.csv\", \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 iterations, the total error is 3920.5\n",
      "The final weight vectors are (starting from input to output layers)\n",
      "The first layer weight vectors: \n",
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485]\n",
      " [-0.70648822 -0.81532281 -0.62747958 -0.30887855]\n",
      " [-0.2064651   0.07763347 -0.16161097  0.370439  ]\n",
      " [-0.5910955   0.75623487 -0.94522481  0.34093502]\n",
      " [-0.1653904   0.11737966 -0.71922612 -0.60379702]\n",
      " [ 0.60148914  0.93652315 -0.37315164  0.38464523]\n",
      " [ 0.7527783   0.78921333 -0.82991158 -0.92189043]\n",
      " [-0.66033916  0.75628501 -0.80330633 -0.15778475]\n",
      " [ 0.91577906  0.06633057  0.38375423 -0.36896874]\n",
      " [ 0.37300186  0.66925134 -0.96342345  0.50028863]\n",
      " [ 0.97772217  0.49633131 -0.43911202  0.57855866]\n",
      " [-0.79354799 -0.10421295  0.81719101 -0.4127717 ]\n",
      " [-0.42444932 -0.73994286 -0.96126608  0.35767107]\n",
      " [-0.57674377 -0.46890668 -0.01685368 -0.89327491]]\n",
      "The second layer weight vectors: \n",
      "[[-0.57669351 -0.64461237]\n",
      " [20.49562127 -1.33225494]\n",
      " [-0.79533114 -0.17188802]\n",
      " [20.70581051 -1.90341312]]\n",
      "The third layer weight vectors: \n",
      "[[-63.0555952 ]\n",
      " [-54.89416851]]\n"
     ]
    }
   ],
   "source": [
    "neural_network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testError = neural_network.predict(\"adultTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testError is\n",
      "1923.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The testError is\")\n",
    "print(testError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b8a29b786a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "print(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
